# 文献批量下载
    两个网站的文章批量下载都是用doi进行文章识别，笔者是通过读取从web of science导出的文献元数据识别doi；若你有文献的doi列表，可直接用程序读取下载。
    因为老师要求要是近两年的文章，笔者尝试过通过从sci-hub和arxiv下载，文章存在大量缺失，这两条技术路线走不通。  
## Science Direct(爱思唯尔,SD) 文献批量下载
    SD网站的下载一次最多下载一页的检索结果（最多20篇），若检索结果成百上千，逐页下载费时费力！  
    SD网站的api相对成熟，并且对机构的个人用户开放。在校学生通过机构登陆SD，然后申请一下就可得到api。
    代码使用:
        - 如果你也是用wos导出的Excel，只用检查下Excel中doi所在列然后替换一下api和修改路径即可。
        - 如果你是有doi列表，你还需要重新写下文件读取函数
        - 程序中有休眠程序设置的是0到20秒随机（我怕SD封我），若你觉得时间太长也可修改；我连续下了1000多篇没被封:)。







## Springer Nature文献批量下载
    我被分到的期刊里有一个Nature子刊。

    BB一下：
    不得不说Springer那网站做的是真恶心，下载链接要一篇一篇点进去下载，而且最方便的那个api只开放给机构，
    不开放给个人（说人话：那个api只开放给学校，不开放给学生，你需要的话就去找图书馆，
    我在图书馆网站根本没看到这个的申请···）
    其他的api接口尝试了好久，一直报错···（是我菜···😭）

    技术路线：
    不过我发现Nature文章的下载网址是固定的，那就走脚本路线了啊😁
    - 用程序打开一个新的浏览器窗口（我设置的是chrome）
    - 让程序先请求一次，窗口会弹出登陆验证，手动进行一下机构登陆
    - 注意登陆完需要去设置关一下chrome浏览器中的打开pdf设置
    （因为chrome浏览器下载PDF默认会打开而不是下载，关闭后不会打开而是自动保存）
    - 上面做完了就可以循环下载了
    
    
